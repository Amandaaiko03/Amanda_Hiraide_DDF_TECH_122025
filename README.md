# üöÄ Case T√©cnico Dadosfera - Engenharia de Dados

**Candidata:** Amanda Aiko
**Data:** Dezembro/2025
**Objetivo:** Constru√ß√£o de uma Plataforma de Dados E2E (End-to-End) para E-commerce.

---

## üóÑÔ∏è Item 1 - Sele√ß√£o da Base de Dados

* **Base Escolhida:** Brazilian E-Commerce Public Dataset by Olist
* **Fonte:** [Kaggle - Olist Dataset](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)

### Justificativa da Escolha
Para atender ao desafio de construir uma Plataforma de Dados robusta, selecionei o dataset da Olist. Esta escolha foi estrat√©gica por tr√™s motivos principais:

1.  **Volumetria e Robustez:** Cont√©m mais de **100.000 pedidos** (2016-2018), superando o requisito t√©cnico e permitindo an√°lises temporais densas.
2.  **Ader√™ncia √† Narrativa:** Cobre todos os desafios sugeridos:
    * *Log√≠stica:* Dados de geolocaliza√ß√£o, CEP e prazos (Estimado vs Real).
    * *Desempenho:* Avalia√ß√£o de vendedores e produtos.
    * *Dados Desestruturados:* Tabela de reviews com coment√°rios reais para NLP/IA.
3.  **Estrutura Relacional:** Dados normalizados em 9 tabelas, ideais para demonstrar modelagem (Star Schema) e SQL complexo.

---

## üìÖ Item 2 - Planejamento e Gest√£o

**Metodologia:** O gerenciamento do projeto foi realizado utilizando a metodologia √°gil **Kanban** atrav√©s do GitHub Projects, permitindo visualiza√ß√£o clara do fluxo de trabalho e entregas incrementais.

**Status do Projeto:**
O quadro abaixo reflete o estado atual das entregas, desde a ingest√£o dos dados at√© a constru√ß√£o do Data App.

![Kanban do Projeto](assets/kanban_project.png)

**Backlog de Melhorias Futuras:**
* Implementa√ß√£o de testes unit√°rios automatizados.
* Pipeline de CI/CD para deploy autom√°tico do Streamlit.

---

## ‚öôÔ∏è Item 2.1 - Integra√ß√£o e Ingest√£o de Dados

Realizei a ingest√£o dos dados na plataforma Dadosfera, focando na tabela fato principal (`olist_order_items`) e nas dimens√µes sat√©lites.

* **Status da Carga:** Sucesso ‚úÖ
* **Volumetria:** 112.650 registros (Requisito > 100k atingido).

### Estrat√©gia de Data Quality na Origem
Para garantir a integridade do schema (*Schema-on-Write*), identifiquei que a ingest√£o padr√£o de CSV poderia falhar na tipagem. Realizei um **pr√©-processamento via Google Sheets**:
* Formata√ß√£o nativa de `shipping_limit_date` para **Datetime**.
* Formata√ß√£o de `price` e `freight_value` para **Decimal**.

Isso eliminou a necessidade de *casting* complexo e acelerou a disponibilidade dos dados na camada Silver.

**Evid√™ncia do Pipeline:**
![Pipeline de Ingest√£o](assets/Pipeline_status.png)

---

## üìö Item 3 - Explora√ß√£o e Governan√ßa (Data Lake)

Organizei o Data Lake seguindo a **Arquitetura Medalh√£o (Medallion Architecture)** e os princ√≠pios FAIR (Findable, Accessible, Interoperable, Reusable).

### 1. Zonas de Dados
Classifiquei os ativos utilizando Tags na plataforma:

* ü•â **Camada Bronze (Landing Zone):** Dados brutos em formato original.
    * *Tags:* `LAKE:LANDING`, `BRONZE`.
* ü•à **Camada Silver (Standardized):** Dados tipados e limpos.
    * *Tag Planejada:* `LAKE:SILVER`.
* ü•á **Camada Gold (Curated):** Dados modelados (Star Schema) para BI.
    * *Tag Planejada:* `LAKE:GOLD`.

### 2. Dicion√°rio de Dados
Cataloguei manualmente os ativos na Dadosfera:

* **`PUBLIC.OLIST_ORDER_ITEMS_DATASET` (Fato):** Documenta√ß√£o de colunas financeiras e convers√£o de tipos.
* **`PUBLIC.OLIST_PRODUCTS_DATASET` (Dimens√£o):** Mapeamento de categorias e dados log√≠sticos (peso/medidas).
* **`PUBLIC.OLIST_CUSTOMERS_DATASET` (Dimens√£o):** Identifica√ß√£o de chaves geogr√°ficas para an√°lise espacial.
* **`PUBLIC.OLIST_ORDER_REVIEWS_DATASET` (Desestruturado):** Identifica√ß√£o de texto livre para GenAI.

---

## ‚úÖ Item 4 - Data Quality & CDM

**Estrat√©gia:** Utilizei a biblioteca **Great Expectations** para validar a camada Bronze antes da promo√ß√£o para Silver, garantindo confiabilidade para os modelos de IA.

### Regras Implementadas (Expectation Suite)
* **Completeness:** `order_id` e `product_id` n√£o podem ser nulos.
* **Validity:** `price` e `freight_value` devem ser positivos (> 0).
* **Consistency:** `seller_id` deve ser do tipo string.

**Resultado:** Sucesso na valida√ß√£o (100%).

**Relat√≥rio de Execu√ß√£o (JSON Output):**
```json
{
    "evaluated_expectations": 5,
    "successful_expectations": 5,
    "unsuccessful_expectations": 0,
    "success_percent": 100.0
}
```

### Evid√™ncias T√©cnicas
* üìÑ **Notebook de C√≥digo:** [Ver data_quality.ipynb](notebooks/data_quality.ipynb)
* üíæ **Arquivo Gerado (CDM):** [Baixar GOLD_SALES_ORDER_CDM.csv](data/gold/GOLD_SALES_ORDER_CDM.csv)


## ü§ñ Item 5 - Sobre o uso de GenAI e LLMs - Processar

**Objetivo:** Transformar dados desestruturados (texto livre dos reviews) em features estruturadas para alimentar dashboards e modelos de churn. A base utilizada foi a `olist_order_reviews`, focando na coluna `review_comment_message`.

**Metodologia (Prompt Engineering):** Utilizei um modelo de LLM para interpretar a sem√¢ntica dos coment√°rios e extrair um objeto JSON contendo:

* **Sentiment Analysis:** Classifica√ß√£o em Positivo/Neutro/Negativo.
* **Category Tagging:** Classifica√ß√£o do problema (ex: Log√≠stica vs Qualidade do Produto).
* **Actionable Insight:** Flag de urg√™ncia para atendimento.

**Exemplo de Input (Desestruturado):**
> "Recebi bem antes do prazo estipulado."

**Exemplo de Output (Feature JSON):**
```json
{
  "sentiment": "Positivo",
  "category": "Log√≠stica",
  "features": {
    "keywords": ["recebi", "bem", "antes"],
    "urgent_action_needed": "N√£o"
  }
}
```

## üìê Item 6 - Modelagem de Dados (Camada Gold)

**Metodologia Escolhida:** Star Schema (Kimball)

Para a modelagem final do Data Warehouse, optei pela metodologia dimensional de Ralph Kimball (Star Schema).

### Justificativa da Escolha:

* **Performance de Leitura:** Como o objetivo final √© alimentar dashboards (Power BI/Metabase) e modelos de IA, o Star Schema reduz o n√∫mero de joins necess√°rios nas consultas, otimizando a performance.
* **Intuitividade:** A separa√ß√£o clara entre Fatos (m√©tricas num√©ricas) e Dimens√µes (contextos descritivos) facilita o self-service BI por usu√°rios de neg√≥cio.
* **Ader√™ncia ao Neg√≥cio:** O cen√°rio de E-commerce adapta-se naturalmente a este modelo: "Vendas" (Fato) ocorrem em um "Tempo", feitas por um "Cliente", contendo um "Produto".

**Estrutura Proposta:** O modelo consiste em uma tabela central de fatos cercada por tabelas de dimens√£o desnormalizadas.

```mermaid
erDiagram
    %% Tabela Fato Central
    Fato_Vendas {
        string order_id FK
        string product_id FK
        string customer_id FK
        string seller_id FK
        datetime data_compra FK
        double valor_venda
        double valor_frete
        int quantidade
    }

    %% Tabelas Dimens√£o
    Dim_Tempo {
        datetime data_id PK
        int ano
        int mes
        int dia
        string dia_semana
        boolean eh_feriado
    }

    Dim_Produto {
        string product_id PK
        string categoria
        double peso_g
        string tamanho_embalagem
    }

    Dim_Cliente {
        string customer_id PK
        string customer_unique_id
        string cidade
        string estado
        string cep_prefixo
    }

    Dim_Vendedor {
        string seller_id PK
        string cidade
        string estado
    }

    %% Relacionamentos (Star Schema)
    Fato_Vendas }|..|| Dim_Tempo : "Data da Compra"
    Fato_Vendas }|..|| Dim_Cliente : "Realizada por"
    Fato_Vendas }|..|| Dim_Produto : "Cont√©m Item"
    Fato_Vendas }|..|| Dim_Vendedor : "Vendido por"

```
## üìä Item 7 - Sobre An√°lise de Dados - Analisar

**Objetivo:** Transformar os dados brutos da camada Bronze em intelig√™ncia de neg√≥cio. Devido √† estrat√©gia de ingest√£o ass√≠ncrona, este primeiro dashboard foca na An√°lise Demogr√°fica e Geogr√°fica (Dimens√£o Clientes), fundamental para o planejamento log√≠stico do e-commerce.

**Artefatos na Dadosfera:**
* **Cole√ß√£o:** `Amanda Aiko - 122025`
* **Dashboard:** `Dashboard Case `

### Visualiza√ß√µes Desenvolvidas (Business Questions)

O dashboard foi estruturado para responder a 5 perguntas estrat√©gicas de neg√≥cio, utilizando 5 tipos de visualiza√ß√µes distintas:

1.  **Indicador de Alcance (Big Number):**
    * **Insight:** Monitoramento do tamanho total da base de clientes √∫nicos (96.096), servindo como norte para metas de crescimento.
    * **Tipo:** KPI Num√©rico.

2.  **Distribui√ß√£o por Estado (Bar Chart Vertical):**
    * **Insight:** Identifica√ß√£o dos polos de demanda. Nota-se a lideran√ßa absoluta de SP, sugerindo onde devem ser alocados os Centros de Distribui√ß√£o (CDs).
    * **Query SQL:** Agrupamento por `customer_state`.

3.  **Top 10 Cidades (Bar Chart Horizontal):**
    * **Insight:** Granularidade municipal para rotas de "Last Mile". Capitais como S√£o Paulo e Rio de Janeiro dominam, mas cidades como Campinas aparecem como hubs secund√°rios importantes.

4.  **Market Share por Macro-Regi√£o (Donut Chart):**
    * **Insight:** Vis√£o executiva da presen√ßa nacional. A regi√£o Sudeste representa 68,65% do total, validando a estrat√©gia de concentra√ß√£o log√≠stica nesta √°rea.
    * **T√©cnica:** Uso de `CASE WHEN` no SQL para criar a dimens√£o "Regi√£o".

5.  **Capilaridade Log√≠stica (Area Chart):**
    * **Insight:** An√°lise de cobertura territorial. Mostra em quantas cidades distintas a marca est√° presente dentro de cada estado. Minas Gerais (MG) destaca-se com alta capilaridade (745 cidades), indicando alta complexidade de entrega no interior.

**Evid√™ncia Visual:**
![Dashboard Case](assets/dashboard.png)

### Queries SQL Utilizadas:

```sql
-- 1. KPI Total de Clientes
SELECT COUNT(DISTINCT customer_unique_id) AS Base_Clientes_Unicos
FROM PUBLIC.TB__6IF8E9__OLIST_CUSTOMERS_DATASET;

-- 2. Top 10 Cidades
SELECT customer_city AS Cidade, COUNT(*) AS Total_Clientes
FROM PUBLIC.TB__6IF8E9__OLIST_CUSTOMERS_DATASET
GROUP BY customer_city ORDER BY Total_Clientes DESC LIMIT 10;

-- 3. Macro-Regi√µes (Case When)
SELECT
    CASE
        WHEN customer_state IN ('SP', 'RJ', 'MG', 'ES') THEN 'Sudeste'
        WHEN customer_state IN ('PR', 'SC', 'RS') THEN 'Sul'
        WHEN customer_state IN ('BA', 'SE', 'AL', 'PE', 'PB', 'RN', 'CE', 'PI', 'MA') THEN 'Nordeste'
        WHEN customer_state IN ('AM', 'RR', 'AP', 'PA', 'TO', 'RO', 'AC') THEN 'Norte'
        ELSE 'Centro-Oeste'
    END AS Regiao,
    COUNT(*) AS Total_Clientes
FROM PUBLIC.TB__6IF8E9__OLIST_CUSTOMERS_DATASET
GROUP BY 1 ORDER BY Total_Clientes DESC;
```
## üîó Item 8 - Sobre Pipelines

**Arquitetura do Pipeline (ELT):** Para garantir o fluxo cont√≠nuo de dados para o Data Lake, implementei um pipeline de **ELT (Extract, Load, Transform)**. Optei pelo padr√£o ELT em vez de ETL para aproveitar o poder de processamento do Data Warehouse (Snowflake) nas etapas de transforma√ß√£o.

### 1. Pipeline de Ingest√£o (Extract & Load)
* **Ferramenta:** Dadosfera Coleta Module.
* **Origem:** Arquivos CSV/Google Sheets (Camada Landing).
* **Destino:** Snowflake Data Warehouse (Camada Bronze).
* **Agendamento:** Trigger Manual (Batch).
* **Status:** Executado com Sucesso ‚úÖ.

### 2. Cataloga√ß√£o do Pipeline
* **Nome do Ativo:** `Pipeline_Ingestao_Olist_Customers`
* **Fun√ß√£o:** Respons√°vel por ler o dataset bruto, validar o schema inicial e persistir os dados na tabela `PUBLIC.TB__..._CUSTOMERS`.
* **Monitoramento:** Logs de execu√ß√£o audit√°veis via interface da plataforma.

### üèÜ Processamento com Snowflake (Snowpark/SQL)
O processamento dos dados foi delegado para a engine do **Snowflake**.

Ao utilizar a arquitetura da Dadosfera, o *compute* utilizado para a ingest√£o e para as queries de visualiza√ß√£o (Item 7) foi o Warehouse do Snowflake.

Isso garante **escalabilidade el√°stica**: se o volume de dados aumentasse de 100 mil para 100 milh√µes de linhas, o pipeline continuaria perform√°tico sem necessidade de refatora√ß√£o de c√≥digo, apenas ajuste de *Warehouse Size*.

**Evid√™ncia do Pipeline:**
![Evid√™ncia Pipeline](assets/pipeline_costomers.png)

## üì± Item 9 - Data App (Streamlit)

**Objetivo:** Democratizar o acesso aos dados atrav√©s de uma aplica√ß√£o web interativa, permitindo que stakeholders explorem os insights de Log√≠stica e IA sem necessidade de conhecimento em SQL.

**Funcionalidades do App:**
1.  **Dashboard de IA (GenAI):** Visualiza√ß√£o interativa da An√°lise de Sentimento dos reviews (Positivo/Negativo) e categoriza√ß√£o autom√°tica.
2.  **Busca Sem√¢ntica:** Ferramenta de pesquisa para encontrar problemas espec√≠ficos nos coment√°rios (ex: "atraso", "quebrado").
3.  **Visualiza√ß√£o da Camada Gold:** Acesso r√°pido aos dados padronizados de vendas (CDM).

**üõ†Ô∏è Stack Tecnol√≥gico:** Python, Streamlit, Plotly Express.

### üåê Acesso ao Projeto
üëâ **[CLIQUE AQUI PARA ACESSAR O APP ONLINE](https://amandahiraideddftech122025-e68frsqu5sytxxjdjngj7f.streamlit.app/)**

*(Caso o link esteja indispon√≠vel devido √† inatividade do servidor gratuito, o c√≥digo fonte completo encontra-se neste reposit√≥rio para execu√ß√£o local)*

**Evid√™ncia Visual:**
![Data App Streamlit](assets/app1.png)

![Data App Streamlit](assets/app2.png)

![Data App Streamlit Dados](assets/app_dados_de_venda.png)

![Data App Streamlit Sobre](assets/app_sobre.png)

----

## üöÄ Item 10 - Apresenta√ß√£o do Case e Nova Arquitetura

**Objetivo:** Apresentar a viabilidade t√©cnica da ado√ß√£o da Dadosfera para substituir a arquitetura legada baseada em microsservi√ßos AWS, com foco na implementa√ß√£o de IA.

### 1. Diagn√≥stico da Arquitetura Atual
A arquitetura atual (Generator ‚Üí Kinesis ‚Üí S3/Redis) √© eficiente para *transporte* de dados em tempo real, mas apresenta lacunas cr√≠ticas para o objetivo de neg√≥cio (**Modelos de IA**):
* **Alta Complexidade Operacional:** Necessidade de gerenciar m√∫ltiplos servi√ßos desconectados (Kinesis Streams, Firehose, Lambdas).
* **Baixa Capacidade Anal√≠tica:** O Redis √© um banco Key-Value, inadequado para an√°lises OLAP ou treinamento de modelos.
* **Falta de Governan√ßa:** Dados brutos no S3 dificultam a garantia de qualidade (Data Quality).

### 2. Solu√ß√£o Proposta (To-Be)
A Prova de Conceito (PoC) realizada demonstra que a Dadosfera atua como uma **Plataforma de Dados Moderna (MDP)**, centralizando a jornada:

**De:**
`Generator` ‚Üí `Kinesis` ‚Üí `Firehose` ‚Üí `S3 (Raw)`

**Para:**
`Generator` ‚Üí **`Dadosfera Pipeline`** ‚Üí **`Snowflake (Gold Layer)`** ‚Üí **`GenAI Module`** ‚Üí **`Streamlit App`**

### 3. Ganhos Estrat√©gicos
1.  **Acelera√ß√£o de IA:** Integra√ß√£o nativa com LLMs para An√°lise de Sentimento (Item 5), algo que exigiria desenvolvimento complexo na arquitetura anterior.
2.  **Democratiza√ß√£o:** Substitui√ß√£o de arquivos t√©cnicos (JSON/CSV) por um Data App interativo (Item 9) para a equipe de neg√≥cios.
3.  **Qualidade Assegurada:** Valida√ß√£o de dados (Great Expectations) integrada ao pipeline, prevenindo "Lixo entra, Lixo sai".


